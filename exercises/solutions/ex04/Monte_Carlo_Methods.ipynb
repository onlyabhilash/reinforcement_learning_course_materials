{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/onlyabhilash/reinforcement_learning_course_materials/blob/main/exercises/solutions/ex04/Monte_Carlo_Methods.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-9dea5c81cd34f5a8",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "GESDLvQKgo4g"
      },
      "source": [
        "# Exercise 04): Monte-Carlo Methods\n",
        "\n",
        "In this exercise we make use of the racetrack environment (racetrack_environment.py) to test Monte-Carlo methods.\n",
        "\n",
        "The racetrack environment is based on the OpenAI Gym interface (https://gym.openai.com/) depicted in the picture below.\n",
        "\n",
        "![](RL_GYM_racetrack.png)\n",
        "\n",
        "(Source: Wiki, https://www.vecteezy.com/free-vector/car)\n",
        "\n",
        "The agent can send an action to the system - our racetrack env - using the `env.step(action)` function to drive the car in the environment which is given by the following racetrack:\n",
        "\n",
        "![](Racetrack1.png)\n",
        "\n",
        "Here, the red line represents the start line and the goal is to move the car within the yellow course to the white finish line without hitting the wall.\n",
        "If the car hits the wall, it will be reset to the start line.\n",
        "The information we get from the step function of the environment are\n",
        "- state consisting of the y- and x-postion (`p_y` and `p_x`) and the velocity in x- and y-direction (`v_y` and `v_x`),\n",
        "- `reward`, which will be -1 per step,\n",
        "- `done`-flag which indicates if the environment is terminated (in our case if the car has reached the finish line),\n",
        "- info (addioninal information, not used here).\n",
        "\n",
        "Our possible actions are to accelerate the car into x- and/or y-direction (positiv or negativ) or do nothing.\n",
        "\n",
        "Accelerate the car will result in chaning the velocity of the car as follows:\n",
        "![](Beschleunigen.png)\n",
        "\n",
        "Breaking the car will result in chaning the velocity of the car as follows:\n",
        "![](break.png)\n",
        "\n",
        "Our possible action-space is therefore `[-1, 0, 1]` which are availabe as tuple or integer number and encoded as exmplained later on.\n",
        "\n",
        "Actions (accelerations in given directions) are encoded according from integer (`a`) to tuple (`a_y`, `a_x`) using the follwoing equations:\n",
        "\n",
        "- `a_y = a//3-1`\n",
        "- `a_x = a%3-1`\n",
        "\n",
        "This is shown in the following diagram:\n",
        "\n",
        "![](Direction_endcoding.png)\n",
        "\n",
        "Please make yourself more familiar with the used environment (racetrack_environment.py) for more informations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vzjc3yJggo4m"
      },
      "source": [
        "For the start, please execute the following cells.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-9c8cfa434031df78",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "d3trIMv3go4m"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import sys\n",
        "from racetrack_environment import RaceTrackEnv\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from tqdm.notebook import tqdm\n",
        "plt.style.use('dark_background')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-46112ad628791ed0",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "wNbjJ9zRgo4o"
      },
      "source": [
        "Execute the follwoing cell to built a race track using the `RaceTrackEnv` as a test scenario.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-ab28c0c5fbe2404e",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "EJId2HLggo4p",
        "outputId": "f6fd407b-9a66-4c28-ddc6-beb9bc201cac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WWWWWWWWWWWW\n",
            "WWWWW-oooooW\n",
            "WWWWW-oooooW\n",
            "WWWWW-oooooW\n",
            "WWWWWWWWWooW\n",
            "WWWWWWWWWooW\n",
            "WWWWW+oooooW\n",
            "WWWWW+oooooW\n",
            "WWWWW+oooooW\n",
            "WWWWWWWWWWWW\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Build the course\n",
        "_course_dim = (8, 10)\n",
        "_inner_wall_dim = (2, 6)\n",
        "\n",
        "def build_uturn_course(course_dim, inner_wall_dim):\n",
        "    \"\"\"\n",
        "    Build a race track for the u-turn street scenario.\n",
        "    Start and finish line are placed in the center top and bottom respectively. The course dimension specifications\n",
        "    do not consider a bounding wall around the track, which is inserted additionally.\n",
        "\n",
        "    \"\"\"\n",
        "    track = []\n",
        "    wall_up_bound = course_dim[0]//2 - inner_wall_dim[0] // 2\n",
        "    wall_bottom_bound = course_dim[0]//2 + inner_wall_dim[0]//2\n",
        "    street_width = course_dim[1]//2 - inner_wall_dim[1]//2\n",
        "    # construct course line by line\n",
        "    for i in range(course_dim[0]):\n",
        "        if i < wall_up_bound:\n",
        "            half_street_len = course_dim[1]//2 - 1\n",
        "            track_row = 'W'*(half_street_len//2+1) + 'W-' + 'o'*(half_street_len-1+half_street_len//2)\n",
        "        elif  wall_up_bound <= i < wall_bottom_bound:\n",
        "            track_row = 'W'*street_width + 'W'*inner_wall_dim[1] + 'o'*street_width\n",
        "        else:\n",
        "            track_row = 'W'*(half_street_len//2+1) + 'W+' + 'o'*(half_street_len-1+half_street_len//2)\n",
        "        track.append(track_row)\n",
        "    # add boundary\n",
        "    track = ['W'*course_dim[1]] + track + ['W'*course_dim[1]]\n",
        "    track = ['W'+s+'W' for s in track]\n",
        "    return track\n",
        "\n",
        "course = build_uturn_course(_course_dim, _inner_wall_dim)\n",
        "track = RaceTrackEnv(course)\n",
        "for row in course:\n",
        "    print(row)\n",
        "\n",
        "pos_map =  track.course  # overlay track course\n",
        "plt.imshow(pos_map, cmap='hot', interpolation='nearest')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-ce1387b114d55595",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "GPBZb5Lngo4q"
      },
      "source": [
        "## 1) Monte-Carlo-Based Policy Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-a3672043edcf93af",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "9RjBDxTYgo4q"
      },
      "source": [
        "Write a first-visit Monte-Carlo algorithm to evaluate the dummy policy as defined below on the U-turn course. The dummy policy turns the car to the right as soon as it stands in front of a wall. Try to understand how the policy works before you start to code.\n",
        "\n",
        "How can we interprete the state values resulting from the evaluation with first-visit Monte-Carlo?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-32d1e89b52d7ea2b",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "pfR7JCHygo4r"
      },
      "source": [
        "## 1) Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-ea22080ba0fc3ad7",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "cSdq_qkIgo4r"
      },
      "source": [
        "Algorithm given below.\n",
        "\n",
        "The simple and deterministic dummy policy will always guarantee the car to reach the finish line. Thus, the state values can be interpreted as the number of timesteps that is necessary to reach the goal from that specific state (i.e. position and velocity) if we are following the policy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-296f673d66265e7c",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "wQkplzs-go4s"
      },
      "outputs": [],
      "source": [
        "### Select course and initialize dummy policy\n",
        "\n",
        "course = build_uturn_course(_course_dim, _inner_wall_dim)\n",
        "track = RaceTrackEnv(course)\n",
        "dummy_slow_pi = np.ones([track.bounds[0], track.bounds[1], 1+2*track.MAX_VELOCITY, 1+2*track.MAX_VELOCITY]) * 4\n",
        "\n",
        "dummy_slow_pi[:track.bounds[0]//2, :, 0 , 0] = 5   # go right\n",
        "dummy_slow_pi[:track.bounds[0]//2, -2:, 0 , :] = 6 # go bottom left\n",
        "dummy_slow_pi[-2:, track.bounds[1]//2:, : , 0] = 0 # go top left\n",
        "\n",
        "pi = dummy_slow_pi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-ac5467fab5f148f4",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "referenced_widgets": [
            "004f408f1a754b7a86e8f7d4645db250"
          ]
        },
        "id": "HHHsjSdFgo4s",
        "outputId": "f1f6a4bf-8f7c-427c-9df8-0e7c59aab76a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "004f408f1a754b7a86e8f7d4645db250",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/500 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# initialize the value function\n",
        "values = np.zeros([track.bounds[0], track.bounds[1], 1+2*track.MAX_VELOCITY, 1+2*track.MAX_VELOCITY])\n",
        "\n",
        "# initialize an empty dict to count the number of visits\n",
        "n_dict = {}\n",
        "\n",
        "# configuration parameters\n",
        "gamma = 1 # discount factor\n",
        "no_episodes = 500 # number of evaluated episodes\n",
        "no_steps = 2000 # number of allowed timesteps per episode\n",
        "\n",
        "for e in tqdm(range(no_episodes), position=0, leave=True):\n",
        "\n",
        "    # initialize variables in which collected data will be stored\n",
        "    states = [] # list of tuples\n",
        "    rewards = [] # list of floats\n",
        "    visited_states = set() # set of tuples\n",
        "    first_visit_list = [] # list of booleans\n",
        "\n",
        "    ### BEGIN SOLUTION\n",
        "\n",
        "    # reset environment and start episode\n",
        "    p, v = track.reset()\n",
        "    for k in range(no_steps):\n",
        "\n",
        "        # unpack the statee information\n",
        "        s_y, s_x = p[0], p[1]\n",
        "        s_vy, s_vx = v[0], v[1]\n",
        "        state_tuple = s_y, s_x, s_vy, s_vx\n",
        "\n",
        "        # save the momentary state\n",
        "        states.append(state_tuple)\n",
        "\n",
        "        # check momentary state for first visit\n",
        "        first_visit_list.append(state_tuple not in visited_states)\n",
        "        visited_states.add(state_tuple)\n",
        "\n",
        "        # choose and perform action\n",
        "        action = track.action_to_tuple(pi[state_tuple])\n",
        "        (p, v), reward, done, _ = track.step(action)\n",
        "\n",
        "        # save received reward\n",
        "        rewards.append(reward)\n",
        "\n",
        "        # terminate the environment if the finish line was passed\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    # learn from the collected data\n",
        "    g = 0\n",
        "    for s, r, first_visit in zip(states[::-1], rewards[::-1], first_visit_list[::-1]): # count backwards\n",
        "        g = gamma * g + r\n",
        "\n",
        "        if first_visit:\n",
        "\n",
        "            # Count visits to this state in n_list\n",
        "            n_dict[s] = n_dict.get(s, 0) + 1\n",
        "\n",
        "            # add new return g to existing value\n",
        "            values[s] += 1/n_dict[s] * (g-values[s])\n",
        "\n",
        "### END SOLUTION\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-6fe53fdd68a6c909",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "6oHUJ0u8go4t"
      },
      "source": [
        "To visualize the result of the evaluation, plot the state values as a function of **position only** (so that you get a two dimensional representation of the state value) and in the form of a tabular represenation and a heatmap. In order to omit dependence of the velocity dimensions, use the minimum of the value function with respect to the velocities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-74fc6bcd5def8261",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "scrolled": false,
        "id": "3fHW4kxsgo4t",
        "outputId": "da54a071-e48f-42ba-ed07-2fed800db69a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "000 000 000 000 000 000 000 000 000 000 000 000\n",
            "000 000 000 000 000 -17 -16 -15 -14 -13 -12 000\n",
            "000 000 000 000 000 -16 -15 -14 -13 -12 -11 000\n",
            "000 000 000 000 000 -15 -14 -13 -12 -11 -10 000\n",
            "000 000 000 000 000 000 000 000 000 000 -09 000\n",
            "000 000 000 000 000 000 000 000 000 000 -08 000\n",
            "000 000 000 000 000 000 000 000 000 000 -07 000\n",
            "000 000 000 000 000 000 000 000 000 000 -06 000\n",
            "000 000 000 000 000 000 -01 -02 -03 -04 -05 000\n",
            "000 000 000 000 000 000 000 000 000 000 000 000\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def text_print_pos_map(_pos_map):\n",
        "    for row in _pos_map:\n",
        "        print(' '.join(x_size*['{}']).format(*[str(int(r)).zfill(3) for r in row]))\n",
        "\n",
        "def plot_pos_map(_pos_map):\n",
        "    plt.imshow(_pos_map, cmap='hot', interpolation='nearest')\n",
        "    plt.show()\n",
        "\n",
        "# calculate minimum value with respect to velocities\n",
        "x_size, y_size = len(course[0]), len(course)\n",
        "pos_map = np.zeros((y_size, x_size))\n",
        "\n",
        "for s_x in range(x_size):\n",
        "    for s_y in range(y_size):\n",
        "        pos_map[s_y, s_x] = np.min(values[s_y, s_x, :, :])\n",
        "\n",
        "text_print_pos_map(pos_map)\n",
        "plot_pos_map(-pos_map)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-54642e38ce9d8a67",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "8HoQO87Pgo4t"
      },
      "source": [
        "## 2) On-Policy $\\varepsilon$-Greedy Control"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-a81f379107be8dd3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "W6Q3We3Ugo4t"
      },
      "source": [
        "Starting with the previously used turn-right-if-wall dummy policy, write an on-policy Monte-Carlo based first-visit $\\varepsilon$-greedy control algorithm to solve the U-turn course. The policy is now stochastic: it does not contain simple action commands for each state, but probabilities for each possible action. Again, please make sure to understand how the stochastic policy works before coding.\n",
        "\n",
        "\n",
        "Make sure to implement an upper bound for episode length (we suggest a boundary of 200 steps). Why do we need a bound like this? What happens to the state values / state-action values if we increase the bound?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-2143fc4c280b5b6f",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "aUJN4-nego4u"
      },
      "source": [
        "## 2) Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-89a131cffdbb5d52",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "5r2-9BVZgo4u"
      },
      "source": [
        "Algorithm given below.\n",
        "\n",
        "As we can see, the dummy policy allows for the initial episode to be solved very fast. After that, the dummy policy is forgotten and it takes some time until the agent is able to solve the problem again.\n",
        "\n",
        "The limitation of the episode length forces the agent to learn at least after the allowed number of steps were taken. If one would increase the limit, this would mainly inflate the accumulated return, resulting in larger negative action values for the visited states. As long as we do NOT find the goal, action values will correlate with the time limit. If we find the goal reproducible, the action values will drift towards their true optimal value independently from the time limit.\n",
        "\n",
        "If we do not implement a time limit and allow the episode to terminate only by reaching the goal, the accumulated negative return will explode (we will get very large numbers). As we try to act greedy (take the highest rated and not the lowest rated action), low action values would suggest that the goal is not to be found on the path taken previously."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-b686db0a0a7aed59",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "scrolled": true,
        "id": "AfKRaB4ugo4u"
      },
      "outputs": [],
      "source": [
        "# dummy policy\n",
        "course = build_uturn_course(_course_dim, _inner_wall_dim)\n",
        "track = RaceTrackEnv(course)\n",
        "\n",
        "dummy_slow_stoch_pi = np.zeros([track.bounds[0], track.bounds[1], 1+2*track.MAX_VELOCITY, 1+2*track.MAX_VELOCITY, 9])\n",
        "\n",
        "dummy_slow_stoch_pi[  :,   :, :, :, 4] = 1 # set probability of doing nothing to one for every state\n",
        "\n",
        "# set probability to go right:\n",
        "dummy_slow_stoch_pi[:track.bounds[0]//2, :, 0 , 0, 5] = 1\n",
        "# set probability to do nothing where we want to go right:\n",
        "dummy_slow_stoch_pi[:track.bounds[0]//2, :, 0 , 0, 4] = 0\n",
        "\n",
        "dummy_slow_stoch_pi[:track.bounds[0]//2, -2:, 0 , :, 6] = 1 # probability to go bottom left\n",
        "dummy_slow_stoch_pi[:track.bounds[0]//2, -2:, 0 , :, 4] = 0\n",
        "\n",
        "dummy_slow_stoch_pi[-2:, track.bounds[1]//2:, : , 0, 0] = 1 # probability to go top left\n",
        "dummy_slow_stoch_pi[-2:, track.bounds[1]//2:, : , 0, 4] = 0\n",
        "\n",
        "pi = dummy_slow_stoch_pi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-9568aa87f2614759",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "scrolled": false,
        "colab": {
          "referenced_widgets": [
            "0b491053578148bfa3d7fcc865ca00b0"
          ]
        },
        "id": "UVQll3BQgo4u",
        "outputId": "6b10800d-b9f1-40ab-a140-2c3246dad458"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b491053578148bfa3d7fcc865ca00b0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "episode:   0%|          | 0/5000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# initialize action_values and counting dict\n",
        "action_values = np.zeros([track.bounds[0], track.bounds[1], 1+2*track.MAX_VELOCITY, 1+2*track.MAX_VELOCITY, 3, 3])\n",
        "n_dict = {}\n",
        "\n",
        "# configuration parameters\n",
        "epsilon = 0.1 # exploration probability\n",
        "gamma = 1 # discount factor\n",
        "no_episodes = 5000 # number of evaluated episodes\n",
        "no_steps = 200 # number of evaluated timesteps per episode\n",
        "track_maps_l = []  # placeholder for tracks\n",
        "\n",
        "track = RaceTrackEnv(course)\n",
        "x_size, y_size = len(course[0]), len(course)\n",
        "\n",
        "for e in tqdm(range(no_episodes), desc='episode', mininterval=2):\n",
        "\n",
        "    # initialize variables in which collected data will be stored\n",
        "    action_states = [] # list of tuples\n",
        "    rewards = [] # list of floats\n",
        "    visited_action_states = set() # set of tuples\n",
        "    first_visit_list = [] # list of booleans\n",
        "\n",
        "    pos_map = np.zeros((y_size, x_size)) # initializes a map that can be plotted\n",
        "\n",
        "    ### BEGIN SOLUTION\n",
        "\n",
        "    p, v = track.reset()\n",
        "    for k in range(no_steps):\n",
        "        s_y, s_x = p[0], p[1]\n",
        "        s_vy, s_vx = v[0], v[1]\n",
        "\n",
        "        pos_map[s_y, s_x] += 1  # mark the visited position on the map\n",
        "\n",
        "        # execute action (either by following the policy, or by exploring randomly)\n",
        "        if epsilon < np.random.rand(1):\n",
        "            action = np.argmax(pi[s_y, s_x, s_vy, s_vx])\n",
        "        else:\n",
        "            action = random.choice(range(9))\n",
        "\n",
        "        # save the action state and check for first visit\n",
        "        a = track.action_to_tuple(action)\n",
        "        action_state = track.state_action((p, v), a)\n",
        "        action_states.append(action_state)\n",
        "        first_visit_list.append(action_state not in visited_action_states)\n",
        "        visited_action_states.add(action_state)\n",
        "\n",
        "        # perform action\n",
        "        (p, v), reward, done, _ = track.step(a)\n",
        "\n",
        "        # save received reward\n",
        "        rewards.append(reward)\n",
        "\n",
        "        # terminate the environment if the finish line was passed\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    # learn from the collected data\n",
        "    g = 0\n",
        "    for r, a_s, first_visit in zip(rewards[::-1], action_states[::-1], first_visit_list[::-1]): # count backwards\n",
        "        g = gamma * g + r\n",
        "\n",
        "        if first_visit:\n",
        "\n",
        "            # Count visits to this state in n_list\n",
        "            n_dict[a_s] = n_dict.get(a_s, 0) +  1\n",
        "\n",
        "            # add new return g to existing value\n",
        "            action_values[a_s] += 1/n_dict[a_s] * (g - action_values[a_s])\n",
        "\n",
        "            # calculate the new action probabilities\n",
        "            u_best = np.argmax(action_values[a_s[:4]])\n",
        "            pi[a_s[:4]] = epsilon / 9\n",
        "            pi[a_s[:4]][u_best] = 1 - epsilon + epsilon / 9\n",
        "\n",
        "\n",
        "    ### END SOLUTION\n",
        "\n",
        "    # optional value map logging\n",
        "    track_maps_l.append(track.course + (pos_map > 0).astype(np.float32))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-ef5799678637f070",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "hUt25WGEgo4u",
        "outputId": "8c125df4-3d13-463c-ae16-49263ca6af57"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "MovieWriter ffmpeg unavailable; trying to use <class 'matplotlib.animation.PillowWriter'> instead.\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# animate visited tracks\n",
        "fig, ax = plt.subplots()\n",
        "image = plt.imshow(track.course, cmap='hot', interpolation='none')\n",
        "time_text = ax.text(0.05, 0.9, '', transform=ax.transAxes)\n",
        "\n",
        "def get_render_func(_track_maps_l):\n",
        "    def animate(it):\n",
        "        track_map = _track_maps_l[it]\n",
        "        #image.set_array(track.course)\n",
        "        image.set_array(track_map)\n",
        "        time_text.set_text(f\"Iteration {it}\")\n",
        "        return image, time_text\n",
        "    return animate\n",
        "\n",
        "def init():\n",
        "    image.set_array(track.course)\n",
        "    return [image]\n",
        "\n",
        "ani = animation.FuncAnimation(fig, get_render_func(track_maps_l), frames=range(0, len(track_maps_l), 100),\n",
        "                              interval=100, blit=True, init_func=init)\n",
        "ani.save(\"solution_2.gif\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-0861c8750a2997ae",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "RYjtX97cgo4v"
      },
      "source": [
        "![SegmentLocal](solution_2.gif \"segment\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-66a45f80f155ca39",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "MaR-rKLWgo4v"
      },
      "source": [
        "Use the code block directly below to test the resulting deterministic greedy policy (several samples are taken in order to show behavior in all different starting positions)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-ba1f0a2326526aeb",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "PiR4kisBgo4v",
        "outputId": "2abbd4c6-56ce-441d-aeab-1af9dadb425d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "MovieWriter ffmpeg unavailable; trying to use <class 'matplotlib.animation.PillowWriter'> instead.\n"
          ]
        }
      ],
      "source": [
        "pos_maps_over_eps_l = []\n",
        "no_episodes = 10\n",
        "for e in range(no_episodes):\n",
        "\n",
        "    pos_map = np.zeros((y_size, x_size))\n",
        "    p, v = track.reset()\n",
        "    for k in range(200):\n",
        "        s_y, s_x = p[0], p[1]\n",
        "        s_vy, s_vx = v[0], v[1]\n",
        "\n",
        "        pos_map[s_y, s_x] += 1  # exploration map\n",
        "\n",
        "        action = np.argmax(pi[s_y, s_x, s_vy, s_vx])\n",
        "        a = track.action_to_tuple(action)\n",
        "        action_state = track.state_action((p, v), a)\n",
        "\n",
        "        (p, v), reward, done, _ = track.step(a)\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "    pos_map = (pos_map > 0).astype(np.int16)\n",
        "    pos_map +=  track.course  # overlay track course\n",
        "    pos_maps_over_eps_l.append(pos_map)\n",
        "\n",
        "ani = animation.FuncAnimation(fig, get_render_func(pos_maps_over_eps_l),\n",
        "                              frames=range(0, len(pos_maps_over_eps_l), 1),\n",
        "                              interval=500, blit=True, init_func=init)\n",
        "ani.save(\"solution_2_2.gif\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-70e585406cef8528",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "v_GBfWoego4v"
      },
      "source": [
        "![SegmentLocal](solution_2_2.gif \"segment\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-679b71dfdf0742d9",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "xX8KdE9Fgo4v"
      },
      "source": [
        "## 3) Off-Policy $\\varepsilon$-Greedy Control"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-c026747de70d5b31",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "IHPkc5lngo4w"
      },
      "source": [
        "Using the dummy-policy from 2) as a behavior policy, write an off-policy Monte-Carlo algorithm with weighted importance sampling.\n",
        "\n",
        "Has the result gotten better or worse? Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-2620db37ac7ac47d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "l_ijSc_ggo4w"
      },
      "source": [
        "## 3) Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-2ac7d4c49a011abb",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "6QtClkB4go4w"
      },
      "source": [
        "Algorithm given below.\n",
        "\n",
        "Since the agent reaches the goal even in the early episodes, one would naively expect the result to outperform the agent from task (2), at least concerning training speed / convergence speed. However, this is not observable.\n",
        "\n",
        "As we do not alternate the behavior policy, exploration and exploitation based on the behavior policy becomes hardly relevant after few episodes of training. E.g. following the behavior policy will rarely result in a velocity bigger than one, which also means that the learned policy will not be able to learn what to do if one is faster than that. Thus, if key elements of the optimal policy are missing from the behavior policy, we can not expect the learned policy to include them.\n",
        "\n",
        "Better options for the behavior policy could be:\n",
        "- alternating the behavior policy once in a while\n",
        "- use the resulting policy from the previous task\n",
        "- using the learned policy from some episodes ago (this can be done via low pass filtering: $\\pi_\\text{behavior} = (1-\\tau) \\cdot \\pi_\\text{behavior} + \\tau \\cdot \\pi_\\text{learned}$ with $0 < \\tau < 1$)\n",
        "\n",
        "Feel free to give it a try 😈  \n",
        "\n",
        "![](https://media.giphy.com/media/UqZ4imFIoljlr5O2sM/giphy.gif)\n",
        "\n",
        "(Source: https://media.giphy.com/media/UqZ4imFIoljlr5O2sM/giphy.gif)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-6f679149b605b3a6",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "ZCUBdA5ggo4w"
      },
      "outputs": [],
      "source": [
        "### Dummy Policy\n",
        "course = build_uturn_course(_course_dim, _inner_wall_dim)\n",
        "track = RaceTrackEnv(course)\n",
        "dummy_slow_stoch_pi = np.zeros([track.bounds[0], track.bounds[1], 1+2*track.MAX_VELOCITY, 1+2*track.MAX_VELOCITY, 9])\n",
        "\n",
        "# as the behavior policy is not alternated, there is no possibility to implement the epsilon parameter later\n",
        "# hence, we need to implemented it right here\n",
        "epsilon = 0.1\n",
        "\n",
        "dummy_slow_stoch_pi[  :,   :, :, :, 4] = 1 - epsilon + epsilon / 9\n",
        "for i in range(9):\n",
        "    if i != 4:\n",
        "        dummy_slow_stoch_pi[  :, :, :, :, i] = epsilon / 9\n",
        "\n",
        "dummy_slow_stoch_pi[:track.bounds[0]//2, :, 0 , 0, 5] = 1-epsilon + epsilon/9\n",
        "dummy_slow_stoch_pi[:track.bounds[0]//2, :, 0 , 0, 4] = epsilon / 9\n",
        "\n",
        "dummy_slow_stoch_pi[:track.bounds[0]//2, -2:, 0 , :, 6] = 1-epsilon + epsilon/9\n",
        "dummy_slow_stoch_pi[:track.bounds[0]//2, -2:, 0 , :, 4] = epsilon / 9\n",
        "\n",
        "dummy_slow_stoch_pi[-2:, track.bounds[1]//2:, : , 0, 0] = 1-epsilon + epsilon/9\n",
        "dummy_slow_stoch_pi[-2:, track.bounds[1]//2:, : , 0, 4] = epsilon / 9\n",
        "\n",
        "behavior_policy = dummy_slow_stoch_pi\n",
        "\n",
        "pi = np.copy(behavior_policy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-a7dfd6b6d5a875bd",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "referenced_widgets": [
            "4372fcfbd52a4dd5adbe001aa7dd271e"
          ]
        },
        "id": "OWru1yBQgo4w",
        "outputId": "12a5c0fd-4667-486c-b9f2-990e7f7c0c3f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4372fcfbd52a4dd5adbe001aa7dd271e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "episode:   0%|          | 0/1000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "MovieWriter ffmpeg unavailable; trying to use <class 'matplotlib.animation.PillowWriter'> instead.\n"
          ]
        }
      ],
      "source": [
        "# initialize action_values and dict of cumulated WIS weights\n",
        "action_values = np.zeros([track.bounds[0], track.bounds[1], 1+2*track.MAX_VELOCITY, 1+2*track.MAX_VELOCITY, 3, 3])\n",
        "c_dict = {}\n",
        "\n",
        "# configuration parameters\n",
        "# epsilon = 0.1 was defined within the behavior policy\n",
        "gamma = 1 # discount factor\n",
        "no_episodes = 1000 # number of evaluated episodes\n",
        "no_steps = 200 # number of evaluated timesteps per episode\n",
        "\n",
        "course = course\n",
        "track = RaceTrackEnv(course)\n",
        "x_size, y_size = len(course[0]), len(course)\n",
        "pos_maps_over_eps_l = []\n",
        "\n",
        "for e in tqdm(range(no_episodes), desc='episode', mininterval=2):\n",
        "\n",
        "    action_states = []\n",
        "    actions = []\n",
        "    rewards = []\n",
        "\n",
        "    pos_map = np.zeros((y_size, x_size))\n",
        "\n",
        "    ### BEGIN SOLUTION\n",
        "\n",
        "    p, v = track.reset()\n",
        "    for k in range(no_steps):\n",
        "        s_y, s_x = p[0], p[1]\n",
        "        s_vy, s_vx = v[0], v[1]\n",
        "\n",
        "        pos_map[s_y, s_x] += 1  # exploration map\n",
        "\n",
        "        if epsilon < np.random.rand(1):\n",
        "            action = np.argmax(behavior_policy[s_y, s_x, s_vy, s_vx])\n",
        "        else:\n",
        "            action = random.choice(range(9))\n",
        "\n",
        "        a = track.action_to_tuple(action)\n",
        "        action_state = track.state_action((p, v), a) # saves the action_state to be used as an index (all values are positive)\n",
        "        actions.append(a) # saves the action as it is applied (acceleration can be negative)\n",
        "        action_states.append(action_state)\n",
        "\n",
        "        (p, v), reward, done, _ = track.step(a)\n",
        "\n",
        "        rewards.append(reward)\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    # Monte-Carlo WIS Update\n",
        "    g = 0\n",
        "    w = 1\n",
        "    for r, a_s, applied_action in zip(rewards[::-1], action_states[::-1], actions[::-1]): # count backwards\n",
        "        g = gamma * g + r\n",
        "\n",
        "        # Count visits to this state in n_list\n",
        "        c_dict[a_s] = c_dict.get(a_s, 0) +  w\n",
        "\n",
        "        # add new return g to existing value\n",
        "        action_values[a_s] += w/c_dict[a_s] * (g - action_values[a_s])\n",
        "\n",
        "        # determine greedy policy\n",
        "        u_best = np.argmax(action_values[a_s[:4]])\n",
        "        pi[a_s[:4]] = 0\n",
        "        pi[a_s[:4]][u_best] = 1\n",
        "\n",
        "        # check if performed action equals greedy action\n",
        "        if applied_action != track.action_to_tuple(u_best):\n",
        "            break\n",
        "\n",
        "        w = w * 1/behavior_policy[a_s[:4]][u_best]\n",
        "\n",
        "    ### END SOLUTION\n",
        "\n",
        "    # code fragment for plotting\n",
        "    pos_map = (pos_map > 0).astype(np.int16)\n",
        "    pos_map +=  track.course  # overlay track course\n",
        "    pos_maps_over_eps_l.append(pos_map)\n",
        "\n",
        "ani = animation.FuncAnimation(fig, get_render_func(pos_maps_over_eps_l),\n",
        "                              frames=range(0, len(pos_maps_over_eps_l), 10),\n",
        "                              interval=100, blit=True, init_func=init)\n",
        "ani.save(\"solution_3_1.gif\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-b419c069a12c73b8",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "91m-uQ1Pgo4x"
      },
      "source": [
        "![SegmentLocal](solution_3_1.gif \"segment\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-e3e001eb425a07bd",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "KwDZ_N_ygo4x",
        "outputId": "c7a94537-3bcc-4e3e-b120-dcfafff99340"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done\n",
            "Sample trajectory on learned policy in episode 0:\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done\n",
            "Sample trajectory on learned policy in episode 1:\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done\n",
            "Sample trajectory on learned policy in episode 2:\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done\n",
            "Sample trajectory on learned policy in episode 3:\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done\n",
            "Sample trajectory on learned policy in episode 4:\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done\n",
            "Sample trajectory on learned policy in episode 5:\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done\n",
            "Sample trajectory on learned policy in episode 6:\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done\n",
            "Sample trajectory on learned policy in episode 7:\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done\n",
            "Sample trajectory on learned policy in episode 8:\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done\n",
            "Sample trajectory on learned policy in episode 9:\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "episodes = 10\n",
        "for e in range(episodes):\n",
        "\n",
        "    pos_map = np.zeros((y_size, x_size))\n",
        "    p, v = track.reset()\n",
        "    for k in range(200):\n",
        "        s_y, s_x = p[0], p[1]\n",
        "        s_vy, s_vx = v[0], v[1]\n",
        "\n",
        "        pos_map[s_y, s_x] += 1  # exploration map\n",
        "\n",
        "        action = np.argmax(pi[s_y, s_x, s_vy, s_vx])\n",
        "\n",
        "        a = track.action_to_tuple(action)\n",
        "        action_state = track.state_action((p, v), a)\n",
        "\n",
        "        (p, v), reward, done, _ = track.step(a)\n",
        "\n",
        "        if done:\n",
        "            print('Done')\n",
        "            break\n",
        "\n",
        "\n",
        "    print('Sample trajectory on learned policy in episode {}:'.format(e))\n",
        "    pos_map = (pos_map > 0).astype(np.int16)\n",
        "    pos_map +=  track.course  # overlay track course\n",
        "    plot_pos_map(pos_map)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-75a92b1a891b9346",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "WX7FxAjfgo4x"
      },
      "source": [
        "## 4) Extra Challenge: A More Complex Course"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-9eb7640363641603",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "-46TbH7Mgo4x"
      },
      "source": [
        "The course given below poses a substantially harder challenge for Monte-Carlo based algorithms. Why? If you want to try solving it yourself, be aware that it may take much longer until a successful policy is found."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-7fdf744535830e4d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "dycEFjqqgo4x",
        "outputId": "bb1896ca-af42-4e0f-802d-79f24faf2a7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WWWWWWWWWWWW\n",
            "Woooo+W-oooW\n",
            "Woooo+W-oooW\n",
            "Woooo+W-oooW\n",
            "WooWWWWWWooW\n",
            "WooWWWWWWooW\n",
            "WooooooooooW\n",
            "WooooooooooW\n",
            "WooooooooooW\n",
            "WWWWWWWWWWWW\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Build the course\n",
        "_course_dim = (8, 10)\n",
        "_inner_wall_dim = (2, 6)\n",
        "\n",
        "def build_rect_course(course_dim, inner_wall_dim):\n",
        "    \"\"\"\n",
        "    Build a race track given specifications for the outer cyclic street and inner wall dimensions.\n",
        "    Start and finish line should be placed in the center top. The course dimension specifications\n",
        "    do not consider a bounding wall around the track, which must be inserted additionally.\n",
        "\n",
        "    Args:\n",
        "        course_dim: 2-tuple, (y-dim, x-dim): The size of the track without outer walls.\n",
        "        inner_wall_dim: 2-tuple (y-dim, x-dim): The size of the inner wall\n",
        "\n",
        "    \"\"\"\n",
        "    track = []\n",
        "    wall_up_bound = course_dim[0]//2 - inner_wall_dim[0] // 2\n",
        "    wall_bottom_bound = course_dim[0]//2 + inner_wall_dim[0]//2\n",
        "    street_width = course_dim[1]//2 - inner_wall_dim[1]//2\n",
        "    # construct course line by line\n",
        "    for i in range(course_dim[0]):\n",
        "        if i < wall_up_bound:\n",
        "            half_street_len = course_dim[1]//2 - 1\n",
        "            track_row = 'o'*half_street_len + '+W-' + 'o'*(half_street_len-1)\n",
        "        elif  wall_up_bound <= i < wall_bottom_bound:\n",
        "            track_row = 'o'*street_width + 'W'*inner_wall_dim[1] + 'o'*street_width\n",
        "        else:\n",
        "            track_row = 'o'*course_dim[1]\n",
        "        track.append(track_row)\n",
        "    # add boundary\n",
        "    track = ['W'*course_dim[1]] + track + ['W'*course_dim[1]]\n",
        "    track = ['W'+s+'W' for s in track]\n",
        "    return track\n",
        "\n",
        "course = build_rect_course(_course_dim, _inner_wall_dim)\n",
        "track = RaceTrackEnv(course)\n",
        "for row in course:\n",
        "    print(row)\n",
        "\n",
        "pos_map =  track.course  # overlay track course\n",
        "plot_pos_map(pos_map)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-6382c23e5d25c036",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "baqrhwtYgo4y"
      },
      "source": [
        "## 4) Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-15500169957f16d3",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "NOFpslp9go4y"
      },
      "source": [
        "Taking four turns to reach the goal is way harder than taking just two turns. Additionally, the state space is a lot larger now, which leads to much more exploration being necessary until all the states are properly evaluated. Although the course is more complicated, the problem description (\"reach the goal\") and the evironment physics (acceleration, momentum and collision) are still the same. Thus, there is no fundamental reason why Monte-Carlo should not be successful here, we just have to be aware that it will take some time.\n",
        "\n",
        "Fortunately, there are still upcoming lectures where more efficient learning algorithms could be discussed ;)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-9f170e15782def02",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "VScWWMJQgo4y"
      },
      "source": [
        "The following screenshot was taken after trying to solve this problem with the same algorithm as presented in task 2). As can be seen, the agent is actually able to solve the racetrack and reach the finish line. But it took about six hours on a very powerful computer to do so.\n",
        "\n",
        "![](FullCourse_MonteCarlo_Solved.png)\n"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Create Assignment",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}