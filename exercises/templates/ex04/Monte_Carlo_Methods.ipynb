{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/onlyabhilash/reinforcement_learning_course_materials/blob/main/exercises/templates/ex04/Monte_Carlo_Methods.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "d3bc190c779f9ded0552cf02bba0e892",
          "grade": false,
          "grade_id": "cell-9dea5c81cd34f5a8",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "cthVswseAOzG"
      },
      "source": [
        "# Exercise 04): Monte-Carlo Methods\n",
        "\n",
        "In this exercise we make use of the racetrack environment (racetrack_environment.py) to test Monte-Carlo methods.\n",
        "\n",
        "The racetrack environment is based on the OpenAI Gym interface (https://gym.openai.com/) depicted in the picture below.\n",
        "\n",
        "![](RL_GYM_racetrack.png)\n",
        "\n",
        "(Source: Wiki, https://www.vecteezy.com/free-vector/car)\n",
        "\n",
        "The agent can send an action to the system - our racetrack env - using the `env.step(action)` function to drive the car in the environment which is given by the following racetrack:\n",
        "\n",
        "![](Racetrack1.png)\n",
        "\n",
        "Here, the red line represents the start line and the goal is to move the car within the yellow course to the white finish line without hitting the wall.\n",
        "If the car hits the wall, it will be reset to the start line.\n",
        "The information we get from the step function of the environment are\n",
        "- state consisting of the y- and x-postion (`p_y` and `p_x`) and the velocity in x- and y-direction (`v_y` and `v_x`),\n",
        "- `reward`, which will be -1 per step,\n",
        "- `done`-flag which indicates if the environment is terminated (in our case if the car has reached the finish line),\n",
        "- info (addioninal information, not used here).\n",
        "\n",
        "Our possible actions are to accelerate the car into x- and/or y-direction (positiv or negativ) or do nothing.\n",
        "\n",
        "Accelerate the car will result in chaning the velocity of the car as follows:\n",
        "![](Beschleunigen.png)\n",
        "\n",
        "Breaking the car will result in chaning the velocity of the car as follows:\n",
        "![](break.png)\n",
        "\n",
        "Our possible action-space is therefore `[-1, 0, 1]` which are availabe as tuple or integer number and encoded as exmplained later on.\n",
        "\n",
        "Actions (accelerations in given directions) are encoded according from integer (`a`) to tuple (`a_y`, `a_x`) using the follwoing equations:\n",
        "\n",
        "- `a_y = a//3-1`\n",
        "- `a_x = a%3-1`\n",
        "\n",
        "This is shown in the following diagram:\n",
        "\n",
        "![](Direction_endcoding.png)\n",
        "\n",
        "Please make yourself more familiar with the used environment (racetrack_environment.py) for more informations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMhzNyrgAOzO"
      },
      "source": [
        "For the start, please execute the following cells.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "75538ea00e2cf600ea10b3c81be0e1ad",
          "grade": false,
          "grade_id": "cell-9c8cfa434031df78",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "phTkHBLdAOzP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import sys\n",
        "from racetrack_environment import RaceTrackEnv\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from tqdm.notebook import tqdm\n",
        "plt.style.use('dark_background')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "5e336a266b7deb26c94551a8fc603a62",
          "grade": false,
          "grade_id": "cell-46112ad628791ed0",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "9pPh6DyhAOzR"
      },
      "source": [
        "Execute the follwoing cell to built a race track using the `RaceTrackEnv` as a test scenario.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f09f31f01a0073294c8e625b3a7c4191",
          "grade": false,
          "grade_id": "cell-ab28c0c5fbe2404e",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "F9csPwrFAOzS"
      },
      "outputs": [],
      "source": [
        "# Build the course\n",
        "_course_dim = (8, 10)\n",
        "_inner_wall_dim = (2, 6)\n",
        "\n",
        "def build_uturn_course(course_dim, inner_wall_dim):\n",
        "    \"\"\"\n",
        "    Build a race track for the u-turn street scenario.\n",
        "    Start and finish line are placed in the center top and bottom respectively. The course dimension specifications\n",
        "    do not consider a bounding wall around the track, which is inserted additionally.\n",
        "\n",
        "    \"\"\"\n",
        "    track = []\n",
        "    wall_up_bound = course_dim[0]//2 - inner_wall_dim[0] // 2\n",
        "    wall_bottom_bound = course_dim[0]//2 + inner_wall_dim[0]//2\n",
        "    street_width = course_dim[1]//2 - inner_wall_dim[1]//2\n",
        "    # construct course line by line\n",
        "    for i in range(course_dim[0]):\n",
        "        if i < wall_up_bound:\n",
        "            half_street_len = course_dim[1]//2 - 1\n",
        "            track_row = 'W'*(half_street_len//2+1) + 'W-' + 'o'*(half_street_len-1+half_street_len//2)\n",
        "        elif  wall_up_bound <= i < wall_bottom_bound:\n",
        "            track_row = 'W'*street_width + 'W'*inner_wall_dim[1] + 'o'*street_width\n",
        "        else:\n",
        "            track_row = 'W'*(half_street_len//2+1) + 'W+' + 'o'*(half_street_len-1+half_street_len//2)\n",
        "        track.append(track_row)\n",
        "    # add boundary\n",
        "    track = ['W'*course_dim[1]] + track + ['W'*course_dim[1]]\n",
        "    track = ['W'+s+'W' for s in track]\n",
        "    return track\n",
        "\n",
        "course = build_uturn_course(_course_dim, _inner_wall_dim)\n",
        "track = RaceTrackEnv(course)\n",
        "for row in course:\n",
        "    print(row)\n",
        "\n",
        "pos_map =  track.course  # overlay track course\n",
        "plt.imshow(pos_map, cmap='hot', interpolation='nearest')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "8b75600d3f638376ef250ff78b7f9ff4",
          "grade": false,
          "grade_id": "cell-ce1387b114d55595",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "92RFb9W8AOzT"
      },
      "source": [
        "## 1) Monte-Carlo-Based Policy Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f272a0b755d8e2a777218421912962d5",
          "grade": false,
          "grade_id": "cell-a3672043edcf93af",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "gg9fQ3e9AOzU"
      },
      "source": [
        "Write a first-visit Monte-Carlo algorithm to evaluate the dummy policy as defined below on the U-turn course. The dummy policy turns the car to the right as soon as it stands in front of a wall. Try to understand how the policy works before you start to code.\n",
        "\n",
        "How can we interprete the state values resulting from the evaluation with first-visit Monte-Carlo?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "fb9337e88dd10e251e1105c85cf20d66",
          "grade": false,
          "grade_id": "cell-32d1e89b52d7ea2b",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "g1enaC7UAOzV"
      },
      "source": [
        "## 1) Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "cb230582893bd38f28bd7d04a0e422ae",
          "grade": false,
          "grade_id": "cell-ea22080ba0fc3ad7",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "T81Rnl94AOzW"
      },
      "source": [
        "Algorithm given below.\n",
        "\n",
        "The simple and deterministic dummy policy will always guarantee the car to reach the finish line. Thus, the state values can be interpreted as the number of timesteps that is necessary to reach the goal from that specific state (i.e. position and velocity) if we are following the policy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2e919458c9c1411d0ee6ac1c2d534bfd",
          "grade": false,
          "grade_id": "cell-296f673d66265e7c",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "iCw-lu82AOzX"
      },
      "outputs": [],
      "source": [
        "### Select course and initialize dummy policy\n",
        "\n",
        "course = build_uturn_course(_course_dim, _inner_wall_dim)\n",
        "track = RaceTrackEnv(course)\n",
        "dummy_slow_pi = np.ones([track.bounds[0], track.bounds[1], 1+2*track.MAX_VELOCITY, 1+2*track.MAX_VELOCITY]) * 4\n",
        "\n",
        "dummy_slow_pi[:track.bounds[0]//2, :, 0 , 0] = 5   # go right\n",
        "dummy_slow_pi[:track.bounds[0]//2, -2:, 0 , :] = 6 # go bottom left\n",
        "dummy_slow_pi[-2:, track.bounds[1]//2:, : , 0] = 0 # go top left\n",
        "\n",
        "pi = dummy_slow_pi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "5b7af3ae44f4d16996a91df5e438d421",
          "grade": false,
          "grade_id": "cell-ac5467fab5f148f4",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "tZHtBzOcAOzY"
      },
      "outputs": [],
      "source": [
        "# initialize the value function\n",
        "values = np.zeros([track.bounds[0], track.bounds[1], 1+2*track.MAX_VELOCITY, 1+2*track.MAX_VELOCITY])\n",
        "\n",
        "# initialize an empty dict to count the number of visits\n",
        "n_dict = {}\n",
        "\n",
        "# configuration parameters\n",
        "gamma = 1 # discount factor\n",
        "no_episodes = 500 # number of evaluated episodes\n",
        "no_steps = 2000 # number of allowed timesteps per episode\n",
        "\n",
        "for e in tqdm(range(no_episodes), position=0, leave=True):\n",
        "\n",
        "    # initialize variables in which collected data will be stored\n",
        "    states = [] # list of tuples\n",
        "    rewards = [] # list of floats\n",
        "    visited_states = set() # set of tuples\n",
        "    first_visit_list = [] # list of booleans\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "950030ffd11e464f008f618a8b94e834",
          "grade": false,
          "grade_id": "cell-6fe53fdd68a6c909",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "7740Y6U6AOzY"
      },
      "source": [
        "To visualize the result of the evaluation, plot the state values as a function of **position only** (so that you get a two dimensional representation of the state value) and in the form of a tabular represenation and a heatmap. In order to omit dependence of the velocity dimensions, use the minimum of the value function with respect to the velocities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "825ce21dcb9c2a4de85dc92fe3d652f3",
          "grade": false,
          "grade_id": "cell-74fc6bcd5def8261",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "BAzXqGpLAOzY"
      },
      "outputs": [],
      "source": [
        "def text_print_pos_map(_pos_map):\n",
        "    for row in _pos_map:\n",
        "        print(' '.join(x_size*['{}']).format(*[str(int(r)).zfill(3) for r in row]))\n",
        "\n",
        "def plot_pos_map(_pos_map):\n",
        "    plt.imshow(_pos_map, cmap='hot', interpolation='nearest')\n",
        "    plt.show()\n",
        "\n",
        "# calculate minimum value with respect to velocities\n",
        "x_size, y_size = len(course[0]), len(course)\n",
        "pos_map = np.zeros((y_size, x_size))\n",
        "\n",
        "for s_x in range(x_size):\n",
        "    for s_y in range(y_size):\n",
        "        pos_map[s_y, s_x] = np.min(values[s_y, s_x, :, :])\n",
        "\n",
        "text_print_pos_map(pos_map)\n",
        "plot_pos_map(-pos_map)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "bb263ef6d6bf6e83fccc3c6c57d56393",
          "grade": false,
          "grade_id": "cell-54642e38ce9d8a67",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "VRknSWgOAOzZ"
      },
      "source": [
        "## 2) On-Policy $\\varepsilon$-Greedy Control"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "12ab33abc90a0c78c45f40f7bb2b57df",
          "grade": false,
          "grade_id": "cell-a81f379107be8dd3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "GZ2Jl-QfAOzZ"
      },
      "source": [
        "Starting with the previously used turn-right-if-wall dummy policy, write an on-policy Monte-Carlo based first-visit $\\varepsilon$-greedy control algorithm to solve the U-turn course. The policy is now stochastic: it does not contain simple action commands for each state, but probabilities for each possible action. Again, please make sure to understand how the stochastic policy works before coding.\n",
        "\n",
        "\n",
        "Make sure to implement an upper bound for episode length (we suggest a boundary of 200 steps). Why do we need a bound like this? What happens to the state values / state-action values if we increase the bound?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "42a41a387c73bb153c4b4dd65ef68c4f",
          "grade": false,
          "grade_id": "cell-2143fc4c280b5b6f",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "pyYz1ADoAOzZ"
      },
      "source": [
        "## 2) Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "af0fd3b2294022f8397d32ab9ccdbbb5",
          "grade": true,
          "grade_id": "cell-89a131cffdbb5d52",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "mCzcQVjFAOzZ"
      },
      "source": [
        "YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "817c14229f5bb2d758ddff8744d6d878",
          "grade": false,
          "grade_id": "cell-b686db0a0a7aed59",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "OhRe_SKqAOzZ"
      },
      "outputs": [],
      "source": [
        "# dummy policy\n",
        "course = build_uturn_course(_course_dim, _inner_wall_dim)\n",
        "track = RaceTrackEnv(course)\n",
        "\n",
        "dummy_slow_stoch_pi = np.zeros([track.bounds[0], track.bounds[1], 1+2*track.MAX_VELOCITY, 1+2*track.MAX_VELOCITY, 9])\n",
        "\n",
        "dummy_slow_stoch_pi[  :,   :, :, :, 4] = 1 # set probability of doing nothing to one for every state\n",
        "\n",
        "# set probability to go right:\n",
        "dummy_slow_stoch_pi[:track.bounds[0]//2, :, 0 , 0, 5] = 1\n",
        "# set probability to do nothing where we want to go right:\n",
        "dummy_slow_stoch_pi[:track.bounds[0]//2, :, 0 , 0, 4] = 0\n",
        "\n",
        "dummy_slow_stoch_pi[:track.bounds[0]//2, -2:, 0 , :, 6] = 1 # probability to go bottom left\n",
        "dummy_slow_stoch_pi[:track.bounds[0]//2, -2:, 0 , :, 4] = 0\n",
        "\n",
        "dummy_slow_stoch_pi[-2:, track.bounds[1]//2:, : , 0, 0] = 1 # probability to go top left\n",
        "dummy_slow_stoch_pi[-2:, track.bounds[1]//2:, : , 0, 4] = 0\n",
        "\n",
        "pi = dummy_slow_stoch_pi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "153a1db3d3671cdb5db4bc978150db37",
          "grade": true,
          "grade_id": "cell-9568aa87f2614759",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "yMdOhcOTAOza"
      },
      "outputs": [],
      "source": [
        "# initialize action_values and counting dict\n",
        "action_values = np.zeros([track.bounds[0], track.bounds[1], 1+2*track.MAX_VELOCITY, 1+2*track.MAX_VELOCITY, 3, 3])\n",
        "n_dict = {}\n",
        "\n",
        "# configuration parameters\n",
        "epsilon = 0.1 # exploration probability\n",
        "gamma = 1 # discount factor\n",
        "no_episodes = 5000 # number of evaluated episodes\n",
        "no_steps = 200 # number of evaluated timesteps per episode\n",
        "track_maps_l = []  # placeholder for tracks\n",
        "\n",
        "track = RaceTrackEnv(course)\n",
        "x_size, y_size = len(course[0]), len(course)\n",
        "\n",
        "for e in tqdm(range(no_episodes), desc='episode', mininterval=2):\n",
        "\n",
        "    # initialize variables in which collected data will be stored\n",
        "    action_states = [] # list of tuples\n",
        "    rewards = [] # list of floats\n",
        "    visited_action_states = set() # set of tuples\n",
        "    first_visit_list = [] # list of booleans\n",
        "\n",
        "    pos_map = np.zeros((y_size, x_size)) # initializes a map that can be plotted\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()\n",
        "\n",
        "    # optional value map logging\n",
        "    track_maps_l.append(track.course + (pos_map > 0).astype(np.float32))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f3a77304ed066b1af2f02fdc182b9a3b",
          "grade": false,
          "grade_id": "cell-ef5799678637f070",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "20GNpnjWAOza"
      },
      "outputs": [],
      "source": [
        "# animate visited tracks\n",
        "fig, ax = plt.subplots()\n",
        "image = plt.imshow(track.course, cmap='hot', interpolation='none')\n",
        "time_text = ax.text(0.05, 0.9, '', transform=ax.transAxes)\n",
        "\n",
        "def get_render_func(_track_maps_l):\n",
        "    def animate(it):\n",
        "        track_map = _track_maps_l[it]\n",
        "        #image.set_array(track.course)\n",
        "        image.set_array(track_map)\n",
        "        time_text.set_text(f\"Iteration {it}\")\n",
        "        return image, time_text\n",
        "    return animate\n",
        "\n",
        "def init():\n",
        "    image.set_array(track.course)\n",
        "    return [image]\n",
        "\n",
        "ani = animation.FuncAnimation(fig, get_render_func(track_maps_l), frames=range(0, len(track_maps_l), 100),\n",
        "                              interval=100, blit=True, init_func=init)\n",
        "ani.save(\"solution_2.gif\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "572cc985329b4a7bf6bea0e91532a9db",
          "grade": false,
          "grade_id": "cell-0861c8750a2997ae",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "AXhFr_XPAOza"
      },
      "source": [
        "![SegmentLocal](solution_2.gif \"segment\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f80985713e5421d2a2f419b230c62e5d",
          "grade": false,
          "grade_id": "cell-66a45f80f155ca39",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "H4bxhcsfAOzb"
      },
      "source": [
        "Use the code block directly below to test the resulting deterministic greedy policy (several samples are taken in order to show behavior in all different starting positions)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "49baa7553ecf87e5c050f88a3c9f92fd",
          "grade": false,
          "grade_id": "cell-ba1f0a2326526aeb",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "9mfelHmiAOzb"
      },
      "outputs": [],
      "source": [
        "pos_maps_over_eps_l = []\n",
        "no_episodes = 10\n",
        "for e in range(no_episodes):\n",
        "\n",
        "    pos_map = np.zeros((y_size, x_size))\n",
        "    p, v = track.reset()\n",
        "    for k in range(200):\n",
        "        s_y, s_x = p[0], p[1]\n",
        "        s_vy, s_vx = v[0], v[1]\n",
        "\n",
        "        pos_map[s_y, s_x] += 1  # exploration map\n",
        "\n",
        "        action = np.argmax(pi[s_y, s_x, s_vy, s_vx])\n",
        "        a = track.action_to_tuple(action)\n",
        "        action_state = track.state_action((p, v), a)\n",
        "\n",
        "        (p, v), reward, done, _ = track.step(a)\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "    pos_map = (pos_map > 0).astype(np.int16)\n",
        "    pos_map +=  track.course  # overlay track course\n",
        "    pos_maps_over_eps_l.append(pos_map)\n",
        "\n",
        "ani = animation.FuncAnimation(fig, get_render_func(pos_maps_over_eps_l),\n",
        "                              frames=range(0, len(pos_maps_over_eps_l), 1),\n",
        "                              interval=500, blit=True, init_func=init)\n",
        "ani.save(\"solution_2_2.gif\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "1da2758dc059e5f98be15995ea0ffb4b",
          "grade": false,
          "grade_id": "cell-70e585406cef8528",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "_e_DHVyvAOzb"
      },
      "source": [
        "![SegmentLocal](solution_2_2.gif \"segment\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "ef63a401fd3977bb15d23b78ac8ff7f0",
          "grade": false,
          "grade_id": "cell-679b71dfdf0742d9",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "KQSEvTqiAOzc"
      },
      "source": [
        "## 3) Off-Policy $\\varepsilon$-Greedy Control"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "a69ecda6b4e16a2db5f3e7fa43d25048",
          "grade": false,
          "grade_id": "cell-c026747de70d5b31",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "7kpKbUqcAOzc"
      },
      "source": [
        "Using the dummy-policy from 2) as a behavior policy, write an off-policy Monte-Carlo algorithm with weighted importance sampling.\n",
        "\n",
        "Has the result gotten better or worse? Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "2532e83b0832734af34182e8f8497bbf",
          "grade": false,
          "grade_id": "cell-2620db37ac7ac47d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "afBpbTR_AOzc"
      },
      "source": [
        "## 3) Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "eef934924ccc6b5b6a252ea062feed79",
          "grade": true,
          "grade_id": "cell-2ac7d4c49a011abb",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "ru7c42Q5AOzc"
      },
      "source": [
        "YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "5344ca769b91fad52abbedca36d6a933",
          "grade": false,
          "grade_id": "cell-6f679149b605b3a6",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "oe_CFkL0AOzc"
      },
      "outputs": [],
      "source": [
        "### Dummy Policy\n",
        "course = build_uturn_course(_course_dim, _inner_wall_dim)\n",
        "track = RaceTrackEnv(course)\n",
        "dummy_slow_stoch_pi = np.zeros([track.bounds[0], track.bounds[1], 1+2*track.MAX_VELOCITY, 1+2*track.MAX_VELOCITY, 9])\n",
        "\n",
        "# as the behavior policy is not alternated, there is no possibility to implement the epsilon parameter later\n",
        "# hence, we need to implemented it right here\n",
        "epsilon = 0.1\n",
        "\n",
        "dummy_slow_stoch_pi[  :,   :, :, :, 4] = 1 - epsilon + epsilon / 9\n",
        "for i in range(9):\n",
        "    if i != 4:\n",
        "        dummy_slow_stoch_pi[  :, :, :, :, i] = epsilon / 9\n",
        "\n",
        "dummy_slow_stoch_pi[:track.bounds[0]//2, :, 0 , 0, 5] = 1-epsilon + epsilon/9\n",
        "dummy_slow_stoch_pi[:track.bounds[0]//2, :, 0 , 0, 4] = epsilon / 9\n",
        "\n",
        "dummy_slow_stoch_pi[:track.bounds[0]//2, -2:, 0 , :, 6] = 1-epsilon + epsilon/9\n",
        "dummy_slow_stoch_pi[:track.bounds[0]//2, -2:, 0 , :, 4] = epsilon / 9\n",
        "\n",
        "dummy_slow_stoch_pi[-2:, track.bounds[1]//2:, : , 0, 0] = 1-epsilon + epsilon/9\n",
        "dummy_slow_stoch_pi[-2:, track.bounds[1]//2:, : , 0, 4] = epsilon / 9\n",
        "\n",
        "behavior_policy = dummy_slow_stoch_pi\n",
        "\n",
        "pi = np.copy(behavior_policy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "9b9e7ea487a0abb0c19adf28cc5f0ead",
          "grade": true,
          "grade_id": "cell-a7dfd6b6d5a875bd",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "9-_zdJpYAOzd"
      },
      "outputs": [],
      "source": [
        "# initialize action_values and dict of cumulated WIS weights\n",
        "action_values = np.zeros([track.bounds[0], track.bounds[1], 1+2*track.MAX_VELOCITY, 1+2*track.MAX_VELOCITY, 3, 3])\n",
        "c_dict = {}\n",
        "\n",
        "# configuration parameters\n",
        "# epsilon = 0.1 was defined within the behavior policy\n",
        "gamma = 1 # discount factor\n",
        "no_episodes = 1000 # number of evaluated episodes\n",
        "no_steps = 200 # number of evaluated timesteps per episode\n",
        "\n",
        "course = course\n",
        "track = RaceTrackEnv(course)\n",
        "x_size, y_size = len(course[0]), len(course)\n",
        "pos_maps_over_eps_l = []\n",
        "\n",
        "for e in tqdm(range(no_episodes), desc='episode', mininterval=2):\n",
        "\n",
        "    action_states = []\n",
        "    actions = []\n",
        "    rewards = []\n",
        "\n",
        "    pos_map = np.zeros((y_size, x_size))\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()\n",
        "\n",
        "    # code fragment for plotting\n",
        "    pos_map = (pos_map > 0).astype(np.int16)\n",
        "    pos_map +=  track.course  # overlay track course\n",
        "    pos_maps_over_eps_l.append(pos_map)\n",
        "\n",
        "ani = animation.FuncAnimation(fig, get_render_func(pos_maps_over_eps_l),\n",
        "                              frames=range(0, len(pos_maps_over_eps_l), 10),\n",
        "                              interval=100, blit=True, init_func=init)\n",
        "ani.save(\"solution_3_1.gif\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "025bb12ae90ce639886644f45b603cc0",
          "grade": false,
          "grade_id": "cell-b419c069a12c73b8",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "RrtwlWIMAOzd"
      },
      "source": [
        "![SegmentLocal](solution_3_1.gif \"segment\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b6b460f156114bd9e76e301c47e564d2",
          "grade": false,
          "grade_id": "cell-e3e001eb425a07bd",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "xzM-v6naAOzd"
      },
      "outputs": [],
      "source": [
        "episodes = 10\n",
        "for e in range(episodes):\n",
        "\n",
        "    pos_map = np.zeros((y_size, x_size))\n",
        "    p, v = track.reset()\n",
        "    for k in range(200):\n",
        "        s_y, s_x = p[0], p[1]\n",
        "        s_vy, s_vx = v[0], v[1]\n",
        "\n",
        "        pos_map[s_y, s_x] += 1  # exploration map\n",
        "\n",
        "        action = np.argmax(pi[s_y, s_x, s_vy, s_vx])\n",
        "\n",
        "        a = track.action_to_tuple(action)\n",
        "        action_state = track.state_action((p, v), a)\n",
        "\n",
        "        (p, v), reward, done, _ = track.step(a)\n",
        "\n",
        "        if done:\n",
        "            print('Done')\n",
        "            break\n",
        "\n",
        "\n",
        "    print('Sample trajectory on learned policy in episode {}:'.format(e))\n",
        "    pos_map = (pos_map > 0).astype(np.int16)\n",
        "    pos_map +=  track.course  # overlay track course\n",
        "    plot_pos_map(pos_map)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "454e031d1c59728e3e90817c0b6ee5fe",
          "grade": false,
          "grade_id": "cell-75a92b1a891b9346",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "wEyhg6cAAOze"
      },
      "source": [
        "## 4) Extra Challenge: A More Complex Course"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f0643d7c199188fe7341ccfb485b235c",
          "grade": false,
          "grade_id": "cell-9eb7640363641603",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "n8R5iTc-AOze"
      },
      "source": [
        "The course given below poses a substantially harder challenge for Monte-Carlo based algorithms. Why? If you want to try solving it yourself, be aware that it may take much longer until a successful policy is found."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "29f8d5a316596da9a4a508934f234191",
          "grade": false,
          "grade_id": "cell-7fdf744535830e4d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "H4Go1IcKAOze"
      },
      "outputs": [],
      "source": [
        "# Build the course\n",
        "_course_dim = (8, 10)\n",
        "_inner_wall_dim = (2, 6)\n",
        "\n",
        "def build_rect_course(course_dim, inner_wall_dim):\n",
        "    \"\"\"\n",
        "    Build a race track given specifications for the outer cyclic street and inner wall dimensions.\n",
        "    Start and finish line should be placed in the center top. The course dimension specifications\n",
        "    do not consider a bounding wall around the track, which must be inserted additionally.\n",
        "\n",
        "    Args:\n",
        "        course_dim: 2-tuple, (y-dim, x-dim): The size of the track without outer walls.\n",
        "        inner_wall_dim: 2-tuple (y-dim, x-dim): The size of the inner wall\n",
        "\n",
        "    \"\"\"\n",
        "    track = []\n",
        "    wall_up_bound = course_dim[0]//2 - inner_wall_dim[0] // 2\n",
        "    wall_bottom_bound = course_dim[0]//2 + inner_wall_dim[0]//2\n",
        "    street_width = course_dim[1]//2 - inner_wall_dim[1]//2\n",
        "    # construct course line by line\n",
        "    for i in range(course_dim[0]):\n",
        "        if i < wall_up_bound:\n",
        "            half_street_len = course_dim[1]//2 - 1\n",
        "            track_row = 'o'*half_street_len + '+W-' + 'o'*(half_street_len-1)\n",
        "        elif  wall_up_bound <= i < wall_bottom_bound:\n",
        "            track_row = 'o'*street_width + 'W'*inner_wall_dim[1] + 'o'*street_width\n",
        "        else:\n",
        "            track_row = 'o'*course_dim[1]\n",
        "        track.append(track_row)\n",
        "    # add boundary\n",
        "    track = ['W'*course_dim[1]] + track + ['W'*course_dim[1]]\n",
        "    track = ['W'+s+'W' for s in track]\n",
        "    return track\n",
        "\n",
        "course = build_rect_course(_course_dim, _inner_wall_dim)\n",
        "track = RaceTrackEnv(course)\n",
        "for row in course:\n",
        "    print(row)\n",
        "\n",
        "pos_map =  track.course  # overlay track course\n",
        "plot_pos_map(pos_map)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "aa7b1016142898eb25e6fe46aa04cde5",
          "grade": false,
          "grade_id": "cell-6382c23e5d25c036",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "1GEjW1O2AOze"
      },
      "source": [
        "## 4) Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "9fb85e183f7f07042f3d34a11c522118",
          "grade": true,
          "grade_id": "cell-15500169957f16d3",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "wRs75DNZAOze"
      },
      "source": [
        "YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "8018e734bbb8831a855f6b55bcd4339c",
          "grade": true,
          "grade_id": "cell-9f170e15782def02",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "clKatPa6AOzf"
      },
      "source": [
        "YOUR ANSWER HERE"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}