{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/onlyabhilash/reinforcement_learning_course_materials/blob/main/exercises/templates/ex11/EligibilityTraces_Hyperopt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17vBJ_QWkEU5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import random\n",
        "import time\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-talk')\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from collections import deque\n",
        "from sklearn.kernel_approximation import RBFSampler\n",
        "import sklearn.pipeline\n",
        "import sklearn.preprocessing\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJlyYzSVkEU_"
      },
      "outputs": [],
      "source": [
        "env = gym.make('MountainCar-v0')\n",
        "observation_examples = np.array([env.observation_space.sample() for x in range(10000)])\n",
        "scaler = sklearn.preprocessing.StandardScaler()\n",
        "scaler.fit(observation_examples)\n",
        "\n",
        "featurizer = sklearn.pipeline.FeatureUnion([\n",
        "    (\"rbf0\", RBFSampler(gamma=5.0, n_components = 100)),\n",
        "    (\"rbf1\", RBFSampler(gamma=2.0, n_components = 100)),\n",
        "    (\"rbf2\", RBFSampler(gamma=1.0, n_components = 100)),\n",
        "    (\"rbf3\", RBFSampler(gamma=0.5, n_components = 100)),\n",
        "    ])\n",
        "featurizer.fit(scaler.transform(observation_examples))\n",
        "\n",
        "\n",
        "def featurize(state):\n",
        "    try:\n",
        "        scaled = scaler.transform([state])\n",
        "    except:\n",
        "        print(state)\n",
        "    featurized = featurizer.transform(scaled)\n",
        "    return featurized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWi771VKkEVB"
      },
      "outputs": [],
      "source": [
        "def sarsa_lambda(nb_episodes, alpha, _lambda):\n",
        "    # alpha = 0.0001\n",
        "    gamma = 1\n",
        "    # _lambda = 0.0\n",
        "    epsilon = 0.15\n",
        "    #nb_episodes = 100\n",
        "\n",
        "    env = gym.make('MountainCar-v0')\n",
        "\n",
        "    state = env.reset()\n",
        "    norm_state = featurize(state)\n",
        "    input_dim = len(norm_state[0])\n",
        "\n",
        "\n",
        "    # define ANN topology\n",
        "    model = Sequential()\n",
        "    model.add(Dense(64, activation='relu', input_dim=input_dim))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(3, activation='linear'))\n",
        "\n",
        "    mse = tf.keras.losses.MeanSquaredError()\n",
        "    opt = SGD(learning_rate=alpha)\n",
        "\n",
        "    needed_steps_lambda = []\n",
        "\n",
        "    for j in tqdm(range(nb_episodes)):\n",
        "        k = 0\n",
        "        rewards = 0\n",
        "\n",
        "        # initialize z to zero;\n",
        "        # needs to be done in a loop because get_weights and gradients are lists\n",
        "        # of arrays that preserve the structure of the ANN\n",
        "        z = model.get_weights()\n",
        "        #print(z)\n",
        "        for i in range(len(z)):\n",
        "            z[i] = z[i] * 0\n",
        "\n",
        "        state = env.reset()\n",
        "        norm_state = featurize(state)\n",
        "\n",
        "        action_values = np.squeeze(model(norm_state).numpy())\n",
        "\n",
        "        # Choose Initial Action greedy\n",
        "        if epsilon < np.random.rand(1):\n",
        "            action = np.argmax(action_values)\n",
        "        else:\n",
        "            action = random.choice(range(3))\n",
        "\n",
        "        while True:\n",
        "            #env.render()\n",
        "\n",
        "            k += 1\n",
        "\n",
        "            ### STEP\n",
        "            next_state, reward, done, _ = env.step(action)\n",
        "            norm_next_state= featurize(next_state)\n",
        "            rewards += reward\n",
        "\n",
        "\n",
        "            action_value = np.squeeze(model(norm_state).numpy())[action]\n",
        "            if done:\n",
        "                target = reward\n",
        "            else:\n",
        "                # epsilon greedy action selection\n",
        "                next_action_values = np.squeeze(model(norm_next_state).numpy())\n",
        "                if epsilon < np.random.rand(1):\n",
        "                    next_action = np.argmax(next_action_values)\n",
        "                else:\n",
        "                    next_action = random.choice(range(3))\n",
        "\n",
        "                next_action_value = next_action_values[next_action]\n",
        "\n",
        "                target = reward + gamma * next_action_value\n",
        "\n",
        "            ### LEARN\n",
        "            delta = target - action_value\n",
        "            #print(delta)\n",
        "            with tf.GradientTape() as tape:\n",
        "                action_values = model(norm_state)\n",
        "                loss = mse(np.array([target]), action_values[0][action])\n",
        "\n",
        "            gradients = tape.gradient(loss, model.trainable_variables)\n",
        "            #print(gradients)\n",
        "            w = model.get_weights()\n",
        "            for i in range(len(z)):\n",
        "                z[i] = gamma * _lambda * z[i] + gradients[i] / delta\n",
        "                w[i] -= alpha * delta * z[i]\n",
        "            model.set_weights(w)\n",
        "            #opt.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "            norm_state = norm_next_state\n",
        "            state = next_state\n",
        "            action = next_action\n",
        "\n",
        "            if done:\n",
        "                needed_steps_lambda.append(k)\n",
        "                #print(f\"episode length {k}\")\n",
        "                if j % 10 == 0:\n",
        "                    #plot_surface(model, input_dim)\n",
        "                    pass\n",
        "                break\n",
        "\n",
        "        env.close()\n",
        "    return needed_steps_lambda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvAH7DJYkEVD"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "#head = [\"alpha\", \"lambda\", \"run\", \"episode_history\"]\n",
        "\n",
        "#file = open('ANN_sarsa_lambda_hyperopt_Samples50_alpha1e-4.csv', 'w')\n",
        "\n",
        "#with file:\n",
        "#    writer = csv.writer(file)\n",
        "#    writer.writerow(head)\n",
        "\n",
        "nb_episodes = 500\n",
        "episodes = np.arange(0, nb_episodes, 1)\n",
        "tries = np.arange(0, 50, 1)\n",
        "\n",
        "#lambda_step = 0.05\n",
        "lambdas = np.array([0.1, 0.25, 0.4])# np.arange(0, 0.3 + lambda_step, lambda_step)\n",
        "\n",
        "#alpha_step0 = 2.5e-5\n",
        "#alphas0 = np.arange(alpha_step0, 1e-4 + alpha_step0, alpha_step0)\n",
        "#alpha_step1 = 2.5e-4\n",
        "#alphas1 = np.arange(alpha_step1, 1e-3 + alpha_step1, alpha_step1)\n",
        "alphas = [0.0001] #np.concatenate((alphas0, alphas1))\n",
        "\n",
        "for alpha in tqdm(alphas):\n",
        "    for _lambda in lambdas:\n",
        "        print(\"starting\")\n",
        "        a = time.time()\n",
        "        results = Parallel(n_jobs=6)(delayed(sarsa_lambda)(nb_episodes, alpha, _lambda) for run in tries)\n",
        "        print(\"ending\")\n",
        "        print(f\"took {time.time()-a} seconds\")\n",
        "\n",
        "        for run, res in enumerate(results):\n",
        "            #res = sarsa_lambda(nb_episodes, alpha, _lambda)\n",
        "            dataseries = np.concatenate(([alpha], [_lambda], [int(run)], res))\n",
        "            file =  open('ANN_sarsa_lambda_hyperopt_Samples50_alpha1e-4.csv', 'a')\n",
        "            with file:\n",
        "                writer = csv.writer(file)\n",
        "                writer.writerow(dataseries)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDCBsUEMkEVD"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "table = None\n",
        "\n",
        "with open('linear_sarsa_lambda.csv') as csv_file:\n",
        "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "    line_count = 0\n",
        "    for row in csv_reader:\n",
        "        if line_count == 0:\n",
        "            print(f'Column names are {\", \".join(row)}')\n",
        "            line_count += 1\n",
        "        else:\n",
        "            if row != []:\n",
        "                if np.any(table == None):\n",
        "                    table = np.array([row])\n",
        "                else:\n",
        "                    table = np.append(table, [row], axis = 0)\n",
        "            line_count += 1\n",
        "    print(f'Processed {line_count} lines.')\n",
        "\n",
        "print(table)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3vIWe8ZkEVE"
      },
      "outputs": [],
      "source": [
        "alphas = np.unique(table[:, 0])\n",
        "lambdas = np.unique(table[:, 1])\n",
        "\n",
        "mean_table = None\n",
        "\n",
        "for alpha in alphas:\n",
        "    for _lambda in lambdas:\n",
        "        accumulate = None\n",
        "        for row in table:\n",
        "            if row[0] == alpha and row[1] == _lambda:\n",
        "                if np.any(accumulate == None):\n",
        "                    accumulate = row[3:].astype(np.float32)\n",
        "                else:\n",
        "                    accumulate += row[3:].astype(np.float32)\n",
        "\n",
        "        accumulate /= 50\n",
        "        mean_row = np.concatenate(([alpha], [_lambda], accumulate))\n",
        "        if np.any(mean_table == None):\n",
        "            mean_table = np.array([mean_row])\n",
        "        else:\n",
        "            mean_table = np.append(mean_table, [mean_row], axis = 0)\n",
        "print(mean_table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyBLAkurkEVF"
      },
      "outputs": [],
      "source": [
        "alphas = np.unique(table[:, 0])\n",
        "lambdas = np.unique(table[:, 1])\n",
        "\n",
        "for alpha in alphas:\n",
        "    fig = plt.figure()\n",
        "    print(f\"alpha = {alpha}\")\n",
        "    for _lambda in lambdas:\n",
        "        for row in mean_table:\n",
        "            if row[0] == alpha and row[1] == _lambda and (_lambda.astype(np.float32) == 0.0 or _lambda.astype(np.float32) == 0.25 or _lambda.astype(np.float32) >= 0.8 and _lambda.astype(np.float32) <= 0.85):\n",
        "                plt.plot(np.squeeze(row[2:].astype(np.float32)), label=fr\"$\\lambda =${_lambda}\")\n",
        "    plt.xlim([000, 500])\n",
        "    plt.ylim([140, 200])\n",
        "    plt.xlabel(\"episodes\")\n",
        "    plt.ylabel(\"episode length\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvRCZwglkEVG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYtqAbF7kEVG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Ccp2Gx8kEVG"
      },
      "outputs": [],
      "source": [
        "observation_examples = np.array([env.observation_space.sample() for x in range(10000)])\n",
        "scaler = sklearn.preprocessing.StandardScaler()\n",
        "scaler.fit(observation_examples)\n",
        "\n",
        "featurizer = sklearn.pipeline.FeatureUnion([\n",
        "    (\"rbf0\", RBFSampler(gamma=5.0, n_components = 100)),\n",
        "    (\"rbf1\", RBFSampler(gamma=2.0, n_components = 100)),\n",
        "    (\"rbf2\", RBFSampler(gamma=1.0, n_components = 100)),\n",
        "    (\"rbf3\", RBFSampler(gamma=0.5, n_components = 100)),\n",
        "    ])\n",
        "featurizer.fit(scaler.transform(observation_examples))\n",
        "\n",
        "\n",
        "def featurize(state, action):\n",
        "    action_vec = np.zeros([3, 1])\n",
        "    action_vec[action] = 1\n",
        "\n",
        "    win = 0\n",
        "    if state[0] > 0.5:\n",
        "        win = 1\n",
        "\n",
        "    try:\n",
        "        scaled = scaler.transform([state])\n",
        "    except:\n",
        "        print(state)\n",
        "    featurized = featurizer.transform(scaled)\n",
        "    featurized = np.reshape(featurized, (-1, 1)) # make column vector\n",
        "\n",
        "    featurized = np.append(featurized, np.array([[1]]), axis = 0)\n",
        "\n",
        "    featurized_vec = np.array([])\n",
        "    featurized_vec = np.expand_dims(featurized_vec, axis=-1)\n",
        "    for a in action_vec:\n",
        "        if a == 1:\n",
        "            featurized_vec = np.append(featurized_vec, featurized, axis = 0)\n",
        "        elif a == 0:\n",
        "            featurized_vec = np.append(featurized_vec, np.zeros([len(featurized), 1]), axis = 0)\n",
        "\n",
        "    return featurized_vec * (1 - win) # append the action to the column vector\n",
        "\n",
        "\n",
        "def policy(state, w, n, epsilon):\n",
        "    feat_states = np.zeros([len(w), n, 1])\n",
        "    q_value = np.zeros([n])\n",
        "\n",
        "    for i in range(n):\n",
        "        feat_state = featurize(state, i)\n",
        "        feat_states[:, i] = feat_state\n",
        "        q_value[i] = np.transpose(feat_state) @ w\n",
        "\n",
        "    if epsilon < np.random.rand(1):\n",
        "        action = np.argmax(q_value)\n",
        "    else:\n",
        "        action = random.choice(range(n))\n",
        "\n",
        "    return feat_states[:, action], action"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DpNE6uWZkEVH"
      },
      "outputs": [],
      "source": [
        "def trueOnline_SARSA(nb_episodes, alpha, _lambda):\n",
        "\n",
        "    #alpha = 0.01\n",
        "    gamma = 1\n",
        "    # _lambda = 0.1 # we call it like that because lambda is a defined command in python\n",
        "    epsilon = 0.15\n",
        "    #nb_episodes = 100\n",
        "\n",
        "    env = gym.make('MountainCar-v0')\n",
        "    state = env.reset()\n",
        "    feat_state = featurize(state, 0)\n",
        "    feat_dims = len(feat_state)\n",
        "\n",
        "    w = np.zeros(feat_dims)\n",
        "    w = np.expand_dims(w, axis=-1)\n",
        "\n",
        "    needed_steps_lambda = []\n",
        "\n",
        "    k = 0\n",
        "    for j in tqdm(range(nb_episodes)):\n",
        "        length = 0\n",
        "\n",
        "        state = env.reset()\n",
        "        feat_state, action = policy(state, w, env.action_space.n, epsilon)\n",
        "\n",
        "        q_old = 0\n",
        "        z = np.zeros_like(feat_state)\n",
        "\n",
        "        while True:\n",
        "            #env.render()\n",
        "            length += 1\n",
        "\n",
        "            # STEP\n",
        "            next_state, reward, done, _ = env.step(action)\n",
        "            feat_next_state, next_action = policy(next_state, w, env.action_space.n, epsilon)\n",
        "\n",
        "\n",
        "            # LEARN\n",
        "            q = np.transpose(w) @ feat_state\n",
        "            q_prime = np.transpose(w) @ feat_next_state\n",
        "            delta = reward + gamma * q_prime - q\n",
        "            z = gamma * _lambda * z + (1 - alpha * gamma * _lambda * np.transpose(feat_state) @ z) * feat_state\n",
        "            w = w + alpha * (delta + q - q_old) * z - alpha * (q - q_old) * feat_state\n",
        "            q_old = q_prime\n",
        "\n",
        "\n",
        "            feat_state = feat_next_state\n",
        "            state = next_state\n",
        "            action = next_action\n",
        "\n",
        "            if done:\n",
        "                #print(f\"Episode: {j}, Length {length}\")\n",
        "                needed_steps_lambda.append(length)\n",
        "                if j % 10 == 0:\n",
        "                    # plot_surface_LSPI(w, feat_dims)\n",
        "                    pass\n",
        "                break\n",
        "\n",
        "        env.close()\n",
        "\n",
        "    return needed_steps_lambda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChP4XJyBkEVI"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "#head = [\"alpha\", \"lambda\", \"run\", \"episode_history\"]\n",
        "\n",
        "#file = open('linear_sarsa_lambda.csv', 'w')\n",
        "\n",
        "#with file:\n",
        "#    writer = csv.writer(file)\n",
        "#    writer.writerow(head)\n",
        "\n",
        "nb_episodes = 500\n",
        "episodes = np.arange(0, nb_episodes, 1)\n",
        "tries = np.arange(0, 50, 1)\n",
        "\n",
        "#lambda_step = 0.05\n",
        "lambdas = np.array([0.8, 0.9, 0.95])# np.arange(0, 0.3 + lambda_step, lambda_step)\n",
        "\n",
        "#alpha_step0 = 2.5e-5\n",
        "#alphas0 = np.arange(alpha_step0, 1e-4 + alpha_step0, alpha_step0)\n",
        "#alpha_step1 = 2.5e-4\n",
        "#alphas1 = np.arange(alpha_step1, 1e-3 + alpha_step1, alpha_step1)\n",
        "alphas = [0.01] #np.concatenate((alphas0, alphas1))\n",
        "\n",
        "for alpha in tqdm(alphas):\n",
        "    for _lambda in lambdas:\n",
        "        print(\"starting\")\n",
        "        a = time.time()\n",
        "        results = Parallel(n_jobs=6)(delayed(trueOnline_SARSA)(nb_episodes, alpha, _lambda) for run in tries)\n",
        "        print(\"ending\")\n",
        "        print(f\"took {time.time()-a} seconds\")\n",
        "\n",
        "        for run, res in enumerate(results):\n",
        "            #res = sarsa_lambda(nb_episodes, alpha, _lambda)\n",
        "            dataseries = np.concatenate(([alpha], [_lambda], [int(run)], res))\n",
        "            file =  open('linear_sarsa_lambda.csv', 'a')\n",
        "            with file:\n",
        "                writer = csv.writer(file)\n",
        "                writer.writerow(dataseries)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHcYS_5LkEVI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}